# -*- coding: utf-8 -*-
"""HW3AD .ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1s2zznWV8ZICUcF9XQU0D9PtuhggCVwk1
"""

import torch

import torchvision
from torchvision.datasets import CIFAR10
import numpy as np

import torchvision
from torchvision.datasets import CIFAR10
import numpy as np

# Define the transformation pipeline for the images
transform = torchvision.transforms.Compose([
    torchvision.transforms.ToTensor(),
    torchvision.transforms.Normalize(mean=list(m), std=list(s))
])

train_data = CIFAR10(root="./train/", train=True, download=True, transform=transform)
test_data = CIFAR10(root="./test/", train=False, download=True, transform=transform)
trains = train_data.data[:100] # This line still operates on raw data, which is fine

trainloader = DataLoader(train_data, batch_size=32, shuffle=True)
testloader = DataLoader(test_data, batch_size=32, shuffle=False)
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

print(f"Shape of trains: {trains.shape}")

raw_mean = np.mean(trains,axis=(0,1,2))
raw_std = np.std(trains,axis=(0,1,2))
print(f"Raw stats: Mean {raw_mean},Std{raw_std}")

trains_n=trains/np.max(trains)
m=np.mean(trains_n,axis=(0,1,2))
s=np.std(trains_n,axis=(0,1,2))
print(f"Normalized Stats (m): {m}, (s):{s}")
trains_nn=(trains_n-m)/s

import torch
import torch.nn as nn
import torch.optim as optim
from torchvision import models, transforms, datasets
import cv2
from PIL import Image

def load_image(img_path: str):
  np_img = cv2.imread(img_path)
  rgb_img=cv2.cvtColor(np_img,cv2.COLOR_BGR2RGB)
  return Image.fromarray(rgb_img)

"""Write your observations. What kind of format was expected by transform for the data to be properly
loadable? What is the meaning of RGB versus L

Answer :
Observations:
* Expected Format: The transforms expect data to be a PIL Image or a numpy array in a specific shape $(H \times W \times C)$.
* RGB vs. L: RGB stands for Red, Green, and Blue, which uses 3 channels to represent full color. L stands for Luminance, which uses only 1 channel to represent a grayscale (black and white) image.
"""

vgg16 = models.vgg16(weights=models.VGG16_Weights.DEFAULT)

vgg16.classifier[6]=nn.Linear(4096,10)

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
vgg16.to(device)
summary(vgg16,input_size=(1,3,224,224))

def check_accuracy(model, loader):
    model.eval()
    correct = 0
    total = 0
    with torch.no_grad():
        for inputs, labels in loader:
            inputs, labels = inputs.to(device), labels.to(device)
            outputs = model(inputs)
            _, predicted = torch.max(outputs.data, 1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()
    return 100 * correct / total
criterion = nn.CrossEntropyLoss()
optimizer = optim.SGD(vgg16.parameters(), lr=0.001, momentum=0.9)

from torch.utils.data import Subset

targets = [1,4,6,8,9]
labmap = {x: i for i,x in enumerate(targets)}

indices = [i for i,label in enumerate(train_data.targets) if label in targets]
test_indices = [i for i, label in enumerate(test_data.targets) if label in targets]

train_subset = Subset(train_data,indices)
test_subset = Subset(test_data, test_indices)

trainloader_sub = DataLoader(train_subset, batch_size=32, shuffle=True)

vgg16_subset = models.vgg16(weights=models.VGG16_Weights.DEFAULT)

vgg16_subset.classifier[6] = nn.Linear(4096, 5) # 5 classes total
vgg16_subset.to(device)

optimizer = optim.SGD(vgg16_subset.parameters(), lr=0.001, momentum=0.9)
criterion = nn.CrossEntropyLoss()

from torch.utils.data import DataLoader

trainloader = DataLoader(train_subset, batch_size=32, shuffle=True)

for inputs, labels in trainloader:
  # Map labels from CIFAR10 original labels to the new target indices
  # labels is a tensor of original CIFAR10 class integers
  labels = torch.tensor([labmap[int(label_item)] for label_item in labels], device=device)
  inputs = inputs.to(device)

new_labels = labels

optimizer.zero_grad()
outputs = vgg16_subset(inputs)
loss = criterion(outputs, new_labels) # Use new_labels here
loss.backward()
optimizer.step()

!pip install torchinfo
from torchinfo import summary

print("Features component:",vgg16.features)
print("AvgPool component: ",vgg16.avgpool)
print("Classifier component:",vgg16.classifier)

print("\n--- VGG16 Children ---")
for i,child in enumerate(vgg16.children()):
  print(f"Child {i}: {child}")

summary(vgg16,input_size=(1,3,224,224))

def get_accuracy(model,loader):
  model.eval()
  num_correct=0.0
  with torch.no_grad():
    for x,y in loader:
      x,y=x.to(device),y.to(device)
      out = model(x)
      _, predicted= torch.max(out,1)
      num_correct += (predicted==y).float().sum()
  return (num_correct/len(loader.dataset)).label_item
vgg_random = models.vgg16(weights=None)
vgg_random.classifier[6] = torch.nn.Linear(4096, 10)
vgg_random.to(device)

optimizer_subset = optim.SGD(vgg16_subset.parameters(), lr=0.001, momentum=0.9)


trainloader = DataLoader(train_subset, batch_size=32, shuffle=True, num_workers=2)

for inputs, labels in trainloader:
    inputs = inputs.to(device)

    new_labels = torch.tensor([labmap[l.item()] for l in labels], device=device)

    optimizer_subset.zero_grad()
    outputs = vgg16_subset(inputs)
    loss = criterion(outputs, new_labels)
    loss.backward()
    optimizer_subset.step()

"""What format was expected by transform for the data to be properly loadable?

Answer:
Based on the implementation of load_image and the error described in pdf,the transformation pipeline(transforms.ToTensor()) expects the data to be in image format or a speciic numpy array shape.
While cv2.imread opens images as Numpy errays they are in BGR formatby default.To make loadable for Pytorch transforms cv2.cvtColor(np_img, cv2.COLOR_BGR2RGB) is used correctlyto convert them to RGB and thn wrapped them in Image.fromarray() to provide expected PIL image format.

what is the meaning of RGB versus L ?
 RGB (Red, Green, Blue): This is a 3-channel color space where each pixel is represented by three values corresponding to the intensity of red, green, and blue light. It is the standard for full-color images.


L (Luminance/Grayscale): This is a 1-channel format where each pixel represents only the brightness (intensity) of the light. It contains no color information and results in a black-and-white image.

How can you find the source code for a PyTorch class?

Jupyter/Colab Shortcut: Type the class name followed by two question marks (e.g., models.vgg16??) in a cell and run it to see the full source code.

Python inspect module: Use import inspect; print(inspect.getsource(models.vgg16)).

Official GitHub: Browse the PyTorch/Vision GitHub repository to see the original implementation of models like VGG16.

Why don't you see the "flatten" layer in torchinfo.summary?

In this code the **summary** output shows sequential features,we dont see a flatten layer becuase :
Functional vs. Module: Flattening in VGG16 is typically performed as a functional call (torch.flatten) inside the forward method rather than being defined as a standalone nn.Module layer (like nn.Flatten).


Children: torchinfo.summary and vgg16.children() only display registered sub-modules. Since torch.flatten is a mathematical operation and not a child module, it is omitted from the structural summary.

Comparison: Pretrained vs. Randomly Initialized VGG16

The Observation: The VGG16 model initialized with weights=VGG16_Weights.DEFAULT will achieve much higher accuracy much faster than the model initialized with weights=None.


Why one is better: * The pretrained model starts with "knowledge" (weights) already optimized to recognize basic visual features like edges, textures, and shapes from the massive ImageNet dataset.

The randomly initialized model starts with completely random weights, meaning it has to learn everything from scratch, which is much more difficult and time-consuming for a complex architecture like VGG16.
"""